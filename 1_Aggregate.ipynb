{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157bd87b",
   "metadata": {},
   "source": [
    "Version 1.0, 1-10-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8af840-a4b5-4c11-985f-96b04fac6c37",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# **1. Skript: Einlesen und Aggregierung der Worddateien (Antworten der VNL-Teilnehmenden)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d80d3b-d2da-457b-adf1-7585eb8a7c77",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**Annahmen und Voraussetzungen in den docx files:**\n",
    "- table name is in the first cell of the first row of each table to be imported\n",
    "- 1 Spalte für Tabellen mit allg. Bemerkungen (nur \"Bemerkungen\")\n",
    "- 5 Spalten für Tabellen mit Bemerkungen zu Artikeln (Artikel, Absatz, Buchstabe, Bemerkung, Textvorschlag)\n",
    "- read table only if table has more than 2 rows (to suppress intro tables)\n",
    "- skript imports the content of all columns from row 4 of each table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207f0d55-1aa4-44f6-8bda-244ea0061aab",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**Skript läuft in Azure Machine Learning Studio\n",
    "Empfohlene Compute-Umgebung: 16 Kerne, 64 GB RAM, 400 GB Festplatte (CPU)\n",
    "Kernel: Python 3.10 SDK v2**\n",
    "\n",
    "**1. Zelle: Installationen von zusätzlichen Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04284f-69f9-4d47-883e-11547fcb081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-docx==1.0.1 pandas==2.1.1 matplotlib==3.7.2 numpy==1.26.0 natsort openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a399ea4e-a1f9-4ac8-b9ef-a17d799863b8",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**2. Zelle: Imports, define parameters, set hardcoded information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223d67d-7487-4ea1-90cb-c71b3f6a5f74",
   "metadata": {
    "gather": {
     "logged": 1756714363672
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import docx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "\n",
    "# Define the folder path in the datastore where your .docx files are stored\n",
    "input_folder_path = \"/YOUR/INPUT/FOLDER/PATH/HERE\"\n",
    "\n",
    "# Define the folder where output documents will be saved\n",
    "output_folder_path = \"/YOUR/OUTPUT/FOLDER/PATH/HERE\"  # Replace with the path to the folder where output documents will be saved\n",
    "\n",
    "# Define output file name:\n",
    "OUTPUT_FILE_NAME = \"output.xlsx\"\n",
    "\n",
    "# specify the custom sheet names (one for every table from the docx files read), rest1, 2, 3 sind ein Schutz gegen weitere unerwartete Tabellen\n",
    "custom_sheet_names = [\n",
    "    \"Sheet name 1\", \"Sheet name 2\", \"Rest1\", \"Rest2\", \"Rest 3\"]\n",
    "\n",
    "# Define keywords for the extraction of the VNL-Teilnehmer (do not change if it works!) (depends on the text in the docx. form)\n",
    "KEYWORDS = [\"Abkürzung der Firma / Organisation\", \"Name / Firma / Organisation\", \"Abréviation de la société / de l’organisation\", \"Abréviation de l’entr. / org.\", \"Nom / entreprise / organisation\", \"Nom / société / organisation\", \"Sigla della ditta / dell’organizzazione\" ,\"Sigla della Ditta / Organizzazione\", \"Nome / Ditta / Organizzazione\", \"Abbreviation Company / Organisation\", \"Name / Company / Organisation\", \"Abkürzung des Eintr. / der Org.\", \"Name / Unternehmen / Organisation\", \"Abréviation de l'entrée / de l'org\", \"Nom / Entreprise / Organisation\", \"Abkürzung des Eintr. / Org\"]  # Add your alternative keywords here\n",
    "\n",
    "# Define column header names for tables (do not change!)\n",
    "HEADER_ALLG = [\n",
    "    \"Organisation\", \"Bemerkung\"]\n",
    "HEADER_ART = [\n",
    "    \"Organisation\", \"Artikel\", \"Absatz\",\n",
    "    \"Buchstabe\", \"Bemerkung\", \"Textvorschlag\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9d1ad-b082-43a6-9a60-0f3940d4ec61",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**3. Zelle: Hauptskript**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321dbce-53c3-4dcf-a356-7e86b7a6b026",
   "metadata": {
    "gather": {
     "logged": 1756715423000
    }
   },
   "outputs": [],
   "source": [
    "# only imports tables with at least 2 rows and more or less than 4 columns (specific exclusion of a table with exactly 4 columns in this VNL)\n",
    "# optimized xlsx and plotting routines\n",
    "#strikethrough text handling (replaces with unicode stricken characters)\n",
    "\n",
    "def striken(text):\n",
    "    return '\\u0336'.join(text) + '\\u0336'\n",
    "\n",
    "def process_run(run):\n",
    "    if run.font.strike:\n",
    "        return striken(run.text)\n",
    "    else:\n",
    "        return run.text\n",
    "\n",
    "def process_cell(cell):\n",
    "    processed_text = []\n",
    "    for paragraph in cell.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            processed_text.append(process_run(run))\n",
    "    return ''.join(processed_text)\n",
    "\n",
    "# Initialize a dictionary to store dataframes for each table\n",
    "table_dataframes = {}\n",
    "\n",
    "# Initialize variables to store processing information\n",
    "num_input_files_processed = 0\n",
    "num_rows_added = {}\n",
    "\n",
    "# Function to check if a row is empty (all cells are empty or all but the first one are empty)\n",
    "def is_empty_row(row):\n",
    "    return all(cell.text.strip() == '' for cell in row.cells)\n",
    "    \n",
    "def extract_organization_abbr(doc):\n",
    "    #keywords = [\"Abkürzung der Firma / Organisation\", \"Name / Firma / Organisation\", \"Abréviation de la société / de l’organisation\", \"Abréviation de l’entr. / org.\", \"Nom / entreprise / organisation\", \"Nom / société / organisation\", \"Sigla della ditta / dell’organizzazione\" ,\"Sigla della Ditta / Organizzazione\", \"Nome / Ditta / Organizzazione\", \"Abbreviation Company / Organisation\", \"Name / Company / Organisation\", \"Abkürzung des Eintr. / der Org.\", \"Name / Unternehmen / Organisation\", \"Abréviation de l'entrée / de l'org\", \"Nom / Entreprise / Organisation\", \"Abkürzung des Eintr. / Org\"]  # Add your alternative keywords here\n",
    "    keywords = KEYWORDS\n",
    "\n",
    "\n",
    "    for keyword in keywords:\n",
    "        for para in doc.paragraphs:\n",
    "            if keyword in para.text:\n",
    "                index = para.text.find(keyword)\n",
    "                if index != -1:\n",
    "                    extracted_text = para.text[index + len(keyword):].strip()[:30]\n",
    "                    # Remove \":\" and spaces until the first character\n",
    "                    cleaned_text = extracted_text.replace(\":\", \"\").lstrip()\n",
    "                    if cleaned_text:\n",
    "                        return cleaned_text\n",
    "    \n",
    "    return ''\n",
    "\n",
    "# Iterate through the .docx files in the input folder\n",
    "for filename in os.listdir(input_folder_path):\n",
    "    if filename.endswith('.docx'):\n",
    "        # print which file is being read\n",
    "        print(f\"File processed: {filename}\")\n",
    "        \n",
    "        # Open the Word document\n",
    "        doc_path = os.path.join(input_folder_path, filename)\n",
    "        doc = docx.Document(doc_path)\n",
    "\n",
    "        # Extract the organization abbreviation from the document\n",
    "        org_abbr = extract_organization_abbr(doc)\n",
    "\n",
    "        # Iterate through the tables in the document\n",
    "        for table in doc.tables:\n",
    "            \n",
    "            # Get the table name (you can customize this part based on your naming convention)\n",
    "            # Here, we assume the table name is in the first cell of the first row\n",
    "            table_name = table.cell(0, 0).text.strip()\n",
    "            \n",
    "            # Convert both the table_name and dictionary keys to lowercase for case-insensitive comparison\n",
    "            table_name = table_name.lower()\n",
    "\n",
    "            # Check if the table name already exists in the dictionary (case-insensitive)\n",
    "            if any(table_name == key.lower() for key in table_dataframes):\n",
    "\n",
    "                # Convert the table data to a pandas DataFrame\n",
    "                table_data = []\n",
    "\n",
    "                # read only if table has more than 2 rows and more or less than 4 columns (to suppress intro tables)\n",
    "                if len(table.rows) > 2 and len(table.rows[2].cells) != 4:\n",
    "                    # Initialize column headers for the current table; suppress this if you have text files with different table formats\n",
    "                    num_columns = len(table.rows[2].cells)\n",
    "                    if num_columns == 1:\n",
    "                        headers = HEADER_ALLG\n",
    "                    #elif num_columns == 4:\n",
    "                        #headers = HEADER_WAHL\n",
    "                    else:\n",
    "                        headers = HEADER_ART\n",
    "\n",
    "                    # Start importing all columns from row 4 (assuming rows are 0-indexed)\n",
    "                    for i, row in enumerate(table.rows):\n",
    "                        if i >= 3 and not is_empty_row(row):  # Skip empty rows\n",
    "                            row_data = [process_cell(cell).strip() for cell in row.cells]\n",
    "\n",
    "                            # Insert organisation abbrev as new cell 1 \n",
    "                            row_data.insert(0, org_abbr)\n",
    "                            table_data.append(row_data)\n",
    "\n",
    "                    df = pd.DataFrame(table_data, columns=headers)\n",
    "\n",
    "                    # Ensure unique column names by appending a suffix\n",
    "                    #unique_cols = pd.Series(df.columns)\n",
    "                    #col_counts = unique_cols.groupby(unique_cols).cumcount()\n",
    "                    #df.columns = [f\"{col}_{count}\" if count > 0 else col for col, count in zip(df.columns, col_counts)]\n",
    "\n",
    "                    # Append the data to the existing dataframe for this table\n",
    "                    table_dataframes[table_name] = pd.concat([table_dataframes[table_name], df], ignore_index=True)\n",
    "\n",
    "                    # Update the number of rows added for this table\n",
    "                    if table_name not in num_rows_added:\n",
    "                        num_rows_added[table_name] = 0\n",
    "                    num_rows_added[table_name] += df.shape[0]\n",
    "\n",
    "            else:\n",
    "                # If the table name doesn't exist, create a new dataframe\n",
    "                table_data = []\n",
    "\n",
    "                # read only if table has more than 2 rows (to suppress intro tables)\n",
    "                if len(table.rows) > 2 and len(table.rows[2].cells) != 4:\n",
    "                    # Initialize column header for the current table; suppress this if you have text files with different table formats\n",
    "                    num_columns = len(table.rows[2].cells)\n",
    "                    if num_columns == 1:\n",
    "                        headers = HEADER_ALLG\n",
    "                    #elif num_columns == 4:\n",
    "                        #headers = HEADER_WAHL\n",
    "                    else:\n",
    "                        headers = HEADER_ART\n",
    "\n",
    "                    # Start importing from row 4 (assuming rows are 0-indexed)\n",
    "                    for i, row in enumerate(table.rows):\n",
    "                        if i >= 3 and not is_empty_row(row):  # Skip empty rows\n",
    "                            row_data = [process_cell(cell).strip() for cell in row.cells]\n",
    "\n",
    "                            # Insert organisation abbrev as new cell 1 \n",
    "                            row_data.insert(0, org_abbr)\n",
    "                            table_data.append(row_data)\n",
    "\n",
    "                    df = pd.DataFrame(table_data, columns=headers)\n",
    "\n",
    "                    # Ensure unique column names by appending a suffix\n",
    "                    #unique_cols = pd.Series(df.columns)\n",
    "                    #col_counts = unique_cols.groupby(unique_cols).cumcount()\n",
    "                    #df.columns = [f\"{col}_{count}\" if count > 0 else col for col, count in zip(df.columns, col_counts)]\n",
    "\n",
    "                    # Add the dataframe to the dictionary\n",
    "                    table_dataframes[table_name] = df\n",
    "                    \n",
    "                    # Update the number of rows added for this table\n",
    "                    if table_name not in num_rows_added:\n",
    "                        num_rows_added[table_name] = 0\n",
    "                    num_rows_added[table_name] += df.shape[0]\n",
    "\n",
    "        num_input_files_processed += 1\n",
    "\n",
    "# Für Diagnose: gebe Anzahl der Dataframes aus (=Anzahl Tabellen), Liste Namen auf\n",
    "print(f\"Eingelesene Tabellennamen: {list(table_dataframes)}\")\n",
    "print(f\"Anzahl eingelesene Tabellen: {len(table_dataframes)}\")\n",
    "        \n",
    "# Create a Pandas Excel writer using openpyxl as the engine\n",
    "output_xlsx_path = os.path.join(output_folder_path, OUTPUT_FILE_NAME)\n",
    "with pd.ExcelWriter(output_xlsx_path, engine=\"openpyxl\") as excel_writer:\n",
    "\n",
    "    # Save individual dataframes as separate tabs in the xlsx file\n",
    "    for i, (table_name, df) in enumerate(table_dataframes.items()):\n",
    "        custom_sheet_name = custom_sheet_names[i]\n",
    "        df.to_excel(excel_writer, sheet_name=custom_sheet_name, index=False)\n",
    "\n",
    "# After closing the Excel file (writer auto-closed by `with`), generate plots\n",
    "for i, (table_name, df) in enumerate(table_dataframes.items()):\n",
    "    custom_sheet_name = custom_sheet_names[i]\n",
    "\n",
    "    if not df.empty and len(df.columns) >= 3:\n",
    "        categories = df.iloc[:, 1].value_counts()\n",
    "        categories = categories.reindex(natsorted(categories.index))\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        categories.plot(kind='bar')\n",
    "        plt.title(f'Bar Chart for {custom_sheet_name}')\n",
    "        plt.xlabel('Artikel')\n",
    "        plt.ylabel('Anzahl Stellungsnahmen')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plot_filename = os.path.join(output_folder_path, f'{table_name}_bar_chart.png')\n",
    "        plt.savefig(plot_filename)\n",
    "        #plt.close()  # Close the plot to free memory\n",
    "\n",
    "# Save processing information to info.txt\n",
    "info_path = os.path.join(output_folder_path, \"info.txt\")\n",
    "with open(info_path, \"w\") as info_file:\n",
    "    info_file.write(f\"# Number of input files processed: {num_input_files_processed}\\n\")\n",
    "    info_file.write(\"\\n# Number of rows added to each table:\\n\")\n",
    "    for table_name, num_rows in num_rows_added.items():\n",
    "        info_file.write(f\"{table_name}: {num_rows}\\n\")\n",
    "\n",
    "print(f\"Tables saved in {output_xlsx_path} with custom sheet names.\")\n",
    "print(\"Processing information saved in info.txt.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "de"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
